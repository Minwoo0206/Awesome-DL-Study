{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임베딩\n",
    "##### 1. 희소 표현 기반 임베딩\n",
    "##### 2. 횟수 기반 임베딩\n",
    "##### 3. 예측 기반 임베딩\n",
    "##### 4. 횟수/예측 기반 임베딩\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 1. 희소 표현 기반 임베딩\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "class2 = pd.read_csv(\"080263/chap10/data/class2.csv\")\n",
    "\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "onehot_encoder = preprocessing.OneHotEncoder(sparse_output=False)\n",
    "\n",
    "var = np.array(class2['class2']).reshape(-1, 1)\n",
    "train_x = onehot_encoder.fit_transform(var)\n",
    "print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 13,\n",
       " 'is': 7,\n",
       " 'last': 8,\n",
       " 'chance': 2,\n",
       " 'and': 0,\n",
       " 'if': 6,\n",
       " 'you': 15,\n",
       " 'do': 3,\n",
       " 'not': 10,\n",
       " 'have': 5,\n",
       " 'will': 14,\n",
       " 'never': 9,\n",
       " 'get': 4,\n",
       " 'any': 1,\n",
       " 'one': 11,\n",
       " 'please': 12}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 횟수 기반 임베딩\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'This is last chance',\n",
    "    'and if you do not have this chance',\n",
    "    'you will never get any chance',\n",
    "    'will you do get this one?',\n",
    "    'please, get this chance'\n",
    "]\n",
    "vect = CountVectorizer()\n",
    "vect.fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transform(['you will never get any chance']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last': 6,\n",
       " 'chance': 1,\n",
       " 'if': 5,\n",
       " 'you': 11,\n",
       " 'do': 2,\n",
       " 'not': 8,\n",
       " 'have': 4,\n",
       " 'will': 10,\n",
       " 'never': 7,\n",
       " 'get': 3,\n",
       " 'any': 0,\n",
       " 'one': 9}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words=['and', 'is', 'please', 'this']).fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 5 stored elements and shape (3, 3)>\n",
      "  Coords\tValues\n",
      "  (0, 1)\t0.224324998974933\n",
      "  (0, 0)\t1.0000000000000002\n",
      "  (1, 1)\t1.0000000000000002\n",
      "  (1, 0)\t0.224324998974933\n",
      "  (2, 2)\t1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "doc = ['I like machine learning', 'I love deep learning', 'I run everyday']\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=1)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(doc)\n",
    "doc_distance = (tfidf_matrix * tfidf_matrix.T)\n",
    "print(doc_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['once',\n",
       "  'upon',\n",
       "  'a',\n",
       "  'time',\n",
       "  'in',\n",
       "  'london',\n",
       "  ',',\n",
       "  'the',\n",
       "  'darlings',\n",
       "  'went',\n",
       "  'out',\n",
       "  'to',\n",
       "  'a',\n",
       "  'dinner',\n",
       "  'party',\n",
       "  'leaving',\n",
       "  'their',\n",
       "  'three',\n",
       "  'children',\n",
       "  'wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  ',',\n",
       "  'and',\n",
       "  'michael',\n",
       "  'at',\n",
       "  'home',\n",
       "  '.'],\n",
       " ['after',\n",
       "  'wendy',\n",
       "  'had',\n",
       "  'tucked',\n",
       "  'her',\n",
       "  'younger',\n",
       "  'brothers',\n",
       "  'jhon',\n",
       "  'and',\n",
       "  'michael',\n",
       "  'to',\n",
       "  'bed',\n",
       "  ',',\n",
       "  'she',\n",
       "  'went',\n",
       "  'to',\n",
       "  'read',\n",
       "  'a',\n",
       "  'book',\n",
       "  '.'],\n",
       " ['she', 'heard', 'a', 'boy', 'sobbing', 'outside', 'her', 'window', '.'],\n",
       " ['he', 'was', 'flying', '.'],\n",
       " ['there', 'was', 'little', 'fairy', 'fluttering', 'around', 'him', '.'],\n",
       " ['wendy', 'opened', 'the', 'window', 'to', 'talk', 'to', 'him', '.'],\n",
       " ['“', 'hello', '!'],\n",
       " ['who', 'are', 'you', '?'],\n",
       " ['why', 'are', 'you', 'crying', '”', ',', 'wendy', 'asked', 'him', '.'],\n",
       " ['“', 'my', 'name', 'is', 'peter', 'pan', '.'],\n",
       " ['my',\n",
       "  'shadow',\n",
       "  'wouldn',\n",
       "  '’',\n",
       "  't',\n",
       "  'stock',\n",
       "  'to',\n",
       "  'me.',\n",
       "  '”',\n",
       "  ',',\n",
       "  'he',\n",
       "  'replied',\n",
       "  '.'],\n",
       " ['she', 'asked', 'him', 'to', 'come', 'in', '.'],\n",
       " ['peter', 'agreed', 'and', 'came', 'inside', 'the', 'room', '.'],\n",
       " ['wendy',\n",
       "  'took',\n",
       "  'his',\n",
       "  'shadow',\n",
       "  'and',\n",
       "  'sewed',\n",
       "  'it',\n",
       "  'to',\n",
       "  'his',\n",
       "  'shoe',\n",
       "  'tips',\n",
       "  '.'],\n",
       " ['now',\n",
       "  'his',\n",
       "  'shadow',\n",
       "  'followed',\n",
       "  'him',\n",
       "  'wherever',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'went',\n",
       "  '!'],\n",
       " ['he',\n",
       "  'was',\n",
       "  'delighted',\n",
       "  'and',\n",
       "  'asked',\n",
       "  'wendy',\n",
       "  '“',\n",
       "  'why',\n",
       "  'don',\n",
       "  '’',\n",
       "  't',\n",
       "  'you',\n",
       "  'come',\n",
       "  'with',\n",
       "  'me',\n",
       "  'to',\n",
       "  'my',\n",
       "  'home',\n",
       "  '.'],\n",
       " ['the', 'neverland', '.'],\n",
       " ['i',\n",
       "  'lived',\n",
       "  'there',\n",
       "  'with',\n",
       "  'my',\n",
       "  'fairy',\n",
       "  'tinker',\n",
       "  'bell.',\n",
       "  '”',\n",
       "  'wendy',\n",
       "  '?'],\n",
       " ['“', 'oh', '!'],\n",
       " ['what', 'a', 'wonderful', 'idea', '!'],\n",
       " ['let', 'me', 'wake', 'up', 'john', 'and', 'micheal', 'too', '.'],\n",
       " ['could', 'you', 'teach', 'us', 'how', 'to', 'fly', '?', '”', '.'],\n",
       " ['“', 'yes', '!'],\n",
       " ['of', 'course', '!'],\n",
       " ['get',\n",
       "  'them',\n",
       "  'we',\n",
       "  'will',\n",
       "  'all',\n",
       "  'fly',\n",
       "  'together.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'replied',\n",
       "  'and',\n",
       "  'so',\n",
       "  'it',\n",
       "  'was',\n",
       "  '.'],\n",
       " ['five',\n",
       "  'little',\n",
       "  'figures',\n",
       "  'flew',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'window',\n",
       "  'of',\n",
       "  'the',\n",
       "  'darlings',\n",
       "  'and',\n",
       "  'headed',\n",
       "  'towards',\n",
       "  'neverland',\n",
       "  '.'],\n",
       " ['as',\n",
       "  'they',\n",
       "  'flew',\n",
       "  'over',\n",
       "  'the',\n",
       "  'island',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'told',\n",
       "  'the',\n",
       "  'children',\n",
       "  'more',\n",
       "  'about',\n",
       "  'his',\n",
       "  'homeland',\n",
       "  '.'],\n",
       " ['“',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'who',\n",
       "  'get',\n",
       "  'lost',\n",
       "  'come',\n",
       "  'and',\n",
       "  'stay',\n",
       "  'with',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'and',\n",
       "  'me',\n",
       "  ',',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'told',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['the', 'indians', 'also', 'live', 'in', 'neverland', '.'],\n",
       " ['the',\n",
       "  'mermaids',\n",
       "  'live',\n",
       "  'in',\n",
       "  'the',\n",
       "  'lagoon',\n",
       "  'around',\n",
       "  'the',\n",
       "  'island',\n",
       "  '.'],\n",
       " ['and',\n",
       "  'a',\n",
       "  'very',\n",
       "  'mean',\n",
       "  'pirate',\n",
       "  'called',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'keeps',\n",
       "  'troubling',\n",
       "  'everyone',\n",
       "  '.'],\n",
       " ['“', 'crocodile', 'bit', 'his', 'one', 'arm', '.'],\n",
       " ['so',\n",
       "  'the',\n",
       "  'captain',\n",
       "  'had',\n",
       "  'to',\n",
       "  'put',\n",
       "  'a',\n",
       "  'hook',\n",
       "  'in',\n",
       "  'its',\n",
       "  'place',\n",
       "  '.'],\n",
       " ['since', 'then', 'he', 'is', 'afraid', 'of', 'crocodiles', '.'],\n",
       " ['and', 'rightly', 'so', '!'],\n",
       " ['if',\n",
       "  'the',\n",
       "  'crocodile',\n",
       "  'ever',\n",
       "  'found',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'it',\n",
       "  'will',\n",
       "  'eat',\n",
       "  'up',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'it',\n",
       "  'couldn',\n",
       "  '’',\n",
       "  't',\n",
       "  'eat',\n",
       "  'last',\n",
       "  'time.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'told',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['soon', 'they', 'landed', 'on', 'the', 'island', '.'],\n",
       " ['and',\n",
       "  'to',\n",
       "  'the',\n",
       "  'surprise',\n",
       "  'of',\n",
       "  'wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  'and',\n",
       "  'michael',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'let',\n",
       "  'them',\n",
       "  'in',\n",
       "  'through',\n",
       "  'a',\n",
       "  'small',\n",
       "  'opening',\n",
       "  'in',\n",
       "  'a',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['inside',\n",
       "  'the',\n",
       "  'tree',\n",
       "  'was',\n",
       "  'a',\n",
       "  'large',\n",
       "  'room',\n",
       "  'with',\n",
       "  'children',\n",
       "  'inside',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['somewhere',\n",
       "  'huddled',\n",
       "  'by',\n",
       "  'the',\n",
       "  'fire',\n",
       "  'in',\n",
       "  'the',\n",
       "  'corner',\n",
       "  'and',\n",
       "  'somewhere',\n",
       "  'playing',\n",
       "  'amongst',\n",
       "  'themselves',\n",
       "  '.'],\n",
       " ['their',\n",
       "  'faces',\n",
       "  'lit',\n",
       "  'up',\n",
       "  'when',\n",
       "  'they',\n",
       "  'saw',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  ',',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  ',',\n",
       "  'and',\n",
       "  'their',\n",
       "  'guests',\n",
       "  '.'],\n",
       " ['“', 'hello', 'everyone', '.'],\n",
       " ['this', 'is', 'wendy', ',', 'jhon', ',', 'and', 'michael', '.'],\n",
       " ['they',\n",
       "  'will',\n",
       "  'be',\n",
       "  'staying',\n",
       "  'with',\n",
       "  'us',\n",
       "  'from',\n",
       "  'now',\n",
       "  'on.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'introduced',\n",
       "  'them',\n",
       "  'to',\n",
       "  'all',\n",
       "  'children',\n",
       "  '.'],\n",
       " ['children', 'welcomed', 'wendy', ',', 'jhon', ',', 'and', 'michael', '.'],\n",
       " ['a', 'few', 'days', 'passed', '.'],\n",
       " ['and', 'they', 'settled', 'into', 'a', 'routine', '.'],\n",
       " ['wendy',\n",
       "  'would',\n",
       "  'take',\n",
       "  'care',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'in',\n",
       "  'the',\n",
       "  'day',\n",
       "  'and',\n",
       "  'would',\n",
       "  'go',\n",
       "  'out',\n",
       "  'with',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'and',\n",
       "  'her',\n",
       "  'brothers',\n",
       "  'in',\n",
       "  'the',\n",
       "  'evening',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'about',\n",
       "  'the',\n",
       "  'island',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'would',\n",
       "  'cook',\n",
       "  'for',\n",
       "  'them',\n",
       "  'and',\n",
       "  'stitch',\n",
       "  'new',\n",
       "  'clothes',\n",
       "  'for',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'even',\n",
       "  'made',\n",
       "  'a',\n",
       "  'lovely',\n",
       "  'new',\n",
       "  'dress',\n",
       "  'for',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  '.'],\n",
       " ['one',\n",
       "  'evening',\n",
       "  ',',\n",
       "  'as',\n",
       "  'they',\n",
       "  'were',\n",
       "  'out',\n",
       "  'exploring',\n",
       "  'the',\n",
       "  'island',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'warned',\n",
       "  'everyone',\n",
       "  'and',\n",
       "  'said',\n",
       "  ',',\n",
       "  '“',\n",
       "  'hide',\n",
       "  '!'],\n",
       " ['hide', '!'],\n",
       " ['pirates', '!'],\n",
       " ['and',\n",
       "  'they',\n",
       "  'have',\n",
       "  'kidnapped',\n",
       "  'the',\n",
       "  'indian',\n",
       "  'princess',\n",
       "  'tiger',\n",
       "  'lily',\n",
       "  '.'],\n",
       " ['they',\n",
       "  'have',\n",
       "  'kept',\n",
       "  'her',\n",
       "  'there',\n",
       "  ',',\n",
       "  'tied',\n",
       "  'up',\n",
       "  'by',\n",
       "  'the',\n",
       "  'rocks',\n",
       "  ',',\n",
       "  'near',\n",
       "  'the',\n",
       "  'water.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'was',\n",
       "  'afraid',\n",
       "  'and',\n",
       "  'the',\n",
       "  'princess',\n",
       "  'would',\n",
       "  'drown',\n",
       "  ',',\n",
       "  'is',\n",
       "  'she',\n",
       "  'fell',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water',\n",
       "  '.'],\n",
       " ['so',\n",
       "  ',',\n",
       "  'in',\n",
       "  'a',\n",
       "  'voice',\n",
       "  'that',\n",
       "  'sounded',\n",
       "  'like',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  ',',\n",
       "  'he',\n",
       "  'shouted',\n",
       "  'instructions',\n",
       "  'to',\n",
       "  'the',\n",
       "  'pirates',\n",
       "  'who',\n",
       "  'guarded',\n",
       "  'her',\n",
       "  ',',\n",
       "  '“',\n",
       "  'you',\n",
       "  'fools',\n",
       "  '!'],\n",
       " ['let', 'her', 'go', 'at', 'once', '!'],\n",
       " ['do',\n",
       "  'it',\n",
       "  'before',\n",
       "  'i',\n",
       "  'come',\n",
       "  'there',\n",
       "  'or',\n",
       "  'else',\n",
       "  'i',\n",
       "  'will',\n",
       "  'throw',\n",
       "  'each',\n",
       "  'one',\n",
       "  'of',\n",
       "  'you',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water.',\n",
       "  '”',\n",
       "  'the',\n",
       "  'pirates',\n",
       "  'got',\n",
       "  'scared',\n",
       "  'and',\n",
       "  'immediately',\n",
       "  'released',\n",
       "  'the',\n",
       "  'princes',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'quickly',\n",
       "  'dived',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water',\n",
       "  'and',\n",
       "  'swam',\n",
       "  'to',\n",
       "  'the',\n",
       "  'safety',\n",
       "  'of',\n",
       "  'her',\n",
       "  'home',\n",
       "  '.'],\n",
       " ['soon',\n",
       "  'everyone',\n",
       "  'found',\n",
       "  'out',\n",
       "  'how',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'had',\n",
       "  'rescued',\n",
       "  'the',\n",
       "  'princess',\n",
       "  '.'],\n",
       " ['when',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'found',\n",
       "  'out',\n",
       "  'how',\n",
       "  'peter',\n",
       "  'had',\n",
       "  'tricked',\n",
       "  'his',\n",
       "  'men',\n",
       "  'he',\n",
       "  'was',\n",
       "  'furious',\n",
       "  '.'],\n",
       " ['and', 'swore', 'to', 'have', 'his', 'revenge', '.'],\n",
       " ['that',\n",
       "  'night',\n",
       "  'wendy',\n",
       "  'told',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  ',',\n",
       "  'that',\n",
       "  'she',\n",
       "  'and',\n",
       "  'her',\n",
       "  'brother',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'go',\n",
       "  'back',\n",
       "  'home',\n",
       "  'since',\n",
       "  'they',\n",
       "  'missed',\n",
       "  'their',\n",
       "  'parents',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'said',\n",
       "  'if',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  'could',\n",
       "  'also',\n",
       "  'return',\n",
       "  'to',\n",
       "  'her',\n",
       "  'world',\n",
       "  'they',\n",
       "  'could',\n",
       "  'find',\n",
       "  'a',\n",
       "  'nice',\n",
       "  'home',\n",
       "  'for',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['peter', 'pan', 'didn', '’', 't', 'want', 'to', 'leave', 'neverland', '.'],\n",
       " ['but',\n",
       "  'the',\n",
       "  'sake',\n",
       "  'of',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  'he',\n",
       "  'agreed',\n",
       "  ',',\n",
       "  'although',\n",
       "  'a',\n",
       "  'bit',\n",
       "  'sadly',\n",
       "  '.'],\n",
       " ['he', 'would', 'miss', 'his', 'friends', 'dearly', '.'],\n",
       " ['the',\n",
       "  'next',\n",
       "  'morning',\n",
       "  'all',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  'left',\n",
       "  'with',\n",
       "  'wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  ',',\n",
       "  'and',\n",
       "  'michael',\n",
       "  '.'],\n",
       " ['but',\n",
       "  'on',\n",
       "  'the',\n",
       "  'way',\n",
       "  ',',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'and',\n",
       "  'his',\n",
       "  'men',\n",
       "  'kidnapped',\n",
       "  'all',\n",
       "  'of',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'tied',\n",
       "  'them',\n",
       "  'and',\n",
       "  'kept',\n",
       "  'them',\n",
       "  'on',\n",
       "  'once',\n",
       "  'of',\n",
       "  'his',\n",
       "  'ships',\n",
       "  '.'],\n",
       " ['as',\n",
       "  'soon',\n",
       "  'as',\n",
       "  'peter',\n",
       "  'found',\n",
       "  'out',\n",
       "  'about',\n",
       "  'it',\n",
       "  'he',\n",
       "  'rushed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'ship',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'swung',\n",
       "  'himself',\n",
       "  'from',\n",
       "  'a',\n",
       "  'tress',\n",
       "  'branch',\n",
       "  'and',\n",
       "  'on',\n",
       "  'to',\n",
       "  'the',\n",
       "  'deck',\n",
       "  'of',\n",
       "  'the',\n",
       "  'ship',\n",
       "  'where',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'were',\n",
       "  'tied',\n",
       "  'up',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'swung',\n",
       "  'his',\n",
       "  'sword',\n",
       "  'bravely',\n",
       "  'and',\n",
       "  'threw',\n",
       "  'over',\n",
       "  'the',\n",
       "  'pirates',\n",
       "  'who',\n",
       "  'tried',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'him',\n",
       "  '.'],\n",
       " ['quickly',\n",
       "  'he',\n",
       "  'released',\n",
       "  'everyone',\n",
       "  'from',\n",
       "  'their',\n",
       "  'captor',\n",
       "  '’',\n",
       "  's',\n",
       "  'ties',\n",
       "  '.'],\n",
       " ['wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  ',',\n",
       "  'michael',\n",
       "  'and',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'helped',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water',\n",
       "  ',',\n",
       "  'where',\n",
       "  'their',\n",
       "  'friends',\n",
       "  'from',\n",
       "  'the',\n",
       "  'indian',\n",
       "  'camp',\n",
       "  'were',\n",
       "  'ready',\n",
       "  'with',\n",
       "  'smaller',\n",
       "  'boats',\n",
       "  'to',\n",
       "  'take',\n",
       "  'them',\n",
       "  'to',\n",
       "  'safety',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'now',\n",
       "  'went',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  '.'],\n",
       " ['“',\n",
       "  'let',\n",
       "  'us',\n",
       "  'finished',\n",
       "  'this',\n",
       "  'forever',\n",
       "  'mr.',\n",
       "  'hook',\n",
       "  '”',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'challenged',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  '.'],\n",
       " ['“', 'yes', '!'],\n",
       " ['peter',\n",
       "  'pan',\n",
       "  ',',\n",
       "  'you',\n",
       "  'have',\n",
       "  'caused',\n",
       "  'me',\n",
       "  'enough',\n",
       "  'trouble',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'time',\n",
       "  'that',\n",
       "  'we',\n",
       "  'finished',\n",
       "  'this.',\n",
       "  '”',\n",
       "  'hook',\n",
       "  'replied',\n",
       "  '.'],\n",
       " ['with',\n",
       "  'his',\n",
       "  'sword',\n",
       "  'drawn',\n",
       "  ',',\n",
       "  'he',\n",
       "  'raced',\n",
       "  'towards',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  '.'],\n",
       " ['quick',\n",
       "  'on',\n",
       "  'his',\n",
       "  'feet',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'stepped',\n",
       "  'aside',\n",
       "  'and',\n",
       "  'pushed',\n",
       "  'hook',\n",
       "  'inside',\n",
       "  'the',\n",
       "  'sea',\n",
       "  'where',\n",
       "  'the',\n",
       "  'crocodile',\n",
       "  'was',\n",
       "  'waiting',\n",
       "  'to',\n",
       "  'eat',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'hook',\n",
       "  '.'],\n",
       " ['everyone',\n",
       "  'rejoiced',\n",
       "  'as',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'was',\n",
       "  'out',\n",
       "  'of',\n",
       "  'their',\n",
       "  'lives',\n",
       "  'forever',\n",
       "  '.'],\n",
       " ['everybody', 'headed', 'back', 'to', 'london', '.'],\n",
       " ['mr.', 'and', 'mrs', '.'],\n",
       " ['darling',\n",
       "  'was',\n",
       "  'so',\n",
       "  'happy',\n",
       "  'to',\n",
       "  'see',\n",
       "  'their',\n",
       "  'children',\n",
       "  'and',\n",
       "  'they',\n",
       "  'agreed',\n",
       "  'to',\n",
       "  'adopt',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  '.'],\n",
       " ['they',\n",
       "  'even',\n",
       "  'asked',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'to',\n",
       "  'come',\n",
       "  'and',\n",
       "  'live',\n",
       "  'with',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['but',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'said',\n",
       "  ',',\n",
       "  'he',\n",
       "  'never',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'up',\n",
       "  ',',\n",
       "  'so',\n",
       "  'he',\n",
       "  'and',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'will',\n",
       "  'go',\n",
       "  'back',\n",
       "  'to',\n",
       "  'neverland',\n",
       "  '.'],\n",
       " ['peter',\n",
       "  'pan',\n",
       "  'promised',\n",
       "  'everyone',\n",
       "  'that',\n",
       "  'he',\n",
       "  'will',\n",
       "  'visit',\n",
       "  'again',\n",
       "  'sometime',\n",
       "  '!'],\n",
       " ['and',\n",
       "  'he',\n",
       "  'flew',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'window',\n",
       "  'with',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'by',\n",
       "  'his',\n",
       "  'side',\n",
       "  '.']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 예측 기반 임베딩\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "sample = open(\"080263/chap10/data/peter.txt\", \"r\", encoding=\"UTF8\")\n",
    "s = sample.read()\n",
    "f = s.replace(\"\\n\", \" \")\n",
    "\n",
    "data = []\n",
    "for i in sent_tokenize(f):\n",
    "    temp = []\n",
    "    for j in word_tokenize(i):\n",
    "        temp.append(j.lower())\n",
    "    data.append(temp)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'peter' 'wendy' - CBOW : 0.07439384\n",
      "Cosine similarity between 'peter' 'hook' - CBOW : 0.027709857\n"
     ]
    }
   ],
   "source": [
    "model1 = Word2Vec(data, min_count=1, vector_size=100, window=5, sg=0)\n",
    "print(\"Cosine similarity between 'peter' 'wendy' - CBOW :\", model1.wv.similarity('peter', 'wendy'))\n",
    "print(\"Cosine similarity between 'peter' 'hook' - CBOW :\", model1.wv.similarity('peter', 'hook'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'peter' 'wendy' - Skip Gram : 0.40088683\n",
      "Cosine similarity between 'peter' 'hook' - Skip Gram : 0.52016735\n"
     ]
    }
   ],
   "source": [
    "model2 = Word2Vec(data, min_count=1, vector_size=100, window=5, sg=1)\n",
    "print(\"Cosine similarity between 'peter' 'wendy' - Skip Gram :\", model2.wv.similarity('peter', 'wendy'))\n",
    "print(\"Cosine similarity between 'peter' 'hook' - Skip Gram :\", model2.wv.similarity('peter', 'hook'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4592452\n",
      "0.043825686\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import FastText\n",
    "\n",
    "model = FastText(\"080263/chap10/data/peter.txt\", vector_size=4, window=3, min_count=1, epochs=10)\n",
    "sim_score = model.wv.similarity('peter', 'wendy')\n",
    "print(sim_score)\n",
    "sim_score = model.wv.similarity('peter', 'hook')\n",
    "print(sim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model_kr = KeyedVectors.load_word2vec_format(\"080263/chap10/data/wiki.ko.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노력함 0.796721339225769\n",
      "노력중 0.7502310872077942\n",
      "노력만 0.7195297479629517\n",
      "노력과 0.7137250900268555\n",
      "노력의 0.6944872140884399\n",
      "노력가 0.6931817531585693\n",
      "노력이나 0.6855085492134094\n",
      "노력없이 0.6761217713356018\n",
      "노력맨 0.6756712198257446\n",
      "노력보다는 0.6753138303756714\n"
     ]
    }
   ],
   "source": [
    "for similar_word in model_kr.similar_by_word('노력'):\n",
    "    print(similar_word[0], similar_word[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('초식동물', 0.7804122567176819)\n"
     ]
    }
   ],
   "source": [
    "similarities = model_kr.most_similar(positive=['동물', '육식동물'], negative=['사람'])\n",
    "print(similarities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/qdcvjm9j4vld91v373k868280000gn/T/ipykernel_17578/2666281902.py:13: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_file, word2vec_glove_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 횟수/예측 기반 임베딩\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_file = datapath(\"/Users/minwoo/dev/Awesome-DL-Study/Deep_Learning_With_Tensorflow/080263/chap10/data/glove.6B.100d.txt\")\n",
    "word2vec_glove_file = get_tmpfile(\"glove.6B.100d.word2vec.txt\")\n",
    "glove2word2vec(glove_file, word2vec_glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('legislation', 0.8072139620780945),\n",
       " ('proposal', 0.7306863069534302),\n",
       " ('senate', 0.7142540812492371),\n",
       " ('bills', 0.704440176486969),\n",
       " ('measure', 0.6958035230636597),\n",
       " ('passed', 0.6906244158744812),\n",
       " ('amendment', 0.6846879720687866),\n",
       " ('provision', 0.6845566630363464),\n",
       " ('plan', 0.6816462874412537),\n",
       " ('clinton', 0.6663140058517456)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
    "model.most_similar('bill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kazushige', 0.4834350347518921),\n",
       " ('askerov', 0.4778185784816742),\n",
       " ('lakpa', 0.46915262937545776),\n",
       " ('ex-gay', 0.45713332295417786),\n",
       " ('tadayoshi', 0.4522107243537903),\n",
       " ('turani', 0.44810065627098083),\n",
       " ('saglam', 0.4469599425792694),\n",
       " ('aijun', 0.4435270130634308),\n",
       " ('adjustors', 0.44235295057296753),\n",
       " ('nyum', 0.4423117935657501)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(negative=['cherry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7698541283607483),\n",
       " ('monarch', 0.6843380331993103),\n",
       " ('throne', 0.6755736470222473),\n",
       " ('daughter', 0.6594556570053101),\n",
       " ('princess', 0.6520534157752991),\n",
       " ('prince', 0.6517034769058228),\n",
       " ('elizabeth', 0.6464518308639526),\n",
       " ('mother', 0.631171703338623),\n",
       " ('emperor', 0.6106470823287964),\n",
       " ('wife', 0.6098655462265015)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "champagne\n",
      "longest\n"
     ]
    }
   ],
   "source": [
    "def analogy(x1, x2, y1):\n",
    "    result = model.most_similar(positive=[x1, x2], negative=[y1])\n",
    "    return result[0][0]\n",
    "\n",
    "print(analogy('beer', 'france', 'australia'))\n",
    "print(analogy('tallest', 'long', 'tall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cereal\n"
     ]
    }
   ],
   "source": [
    "print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 트랜스포머 어텐션\n",
    "##### 1. seq2seq\n",
    "##### 2. Bert\n",
    "##### 3. 엘모"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq2seq\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import unicodedata\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "     return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1\", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.rstrip().strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "sp_sentence = u\"¿ Puedo tomar prestado este libro?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')] for l in lines[:num_examples]]\n",
    "    return zip(*word_pairs)\n",
    "\n",
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    return tensor, lang_tokenizer\n",
    "\n",
    "def load_dataset(path, num_examples=None):\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 30000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(\"080263/chap10/data/spa.txt\", num_examples)\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train) // BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "vocab_targ_size = len(targ_lang.word_index) + 1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(\n",
    "            self.enc_units,\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            recurrent_initializer='glorot_uniform'\n",
    "        )\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "    \n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(EDAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(\n",
    "            self.dec_units,\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            recurrent_initializer='glorot_uniform'\n",
    "        )\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        self.attention = EDAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights\n",
    "    \n",
    "decoder = Decoder(vocab_targ_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ += mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(\n",
    "    optimizer=optimizer,\n",
    "    encoder=encoder,\n",
    "    decoder=decoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 8.2511\n",
      "Epoch 1 Batch 100 Loss 2.9450\n",
      "Epoch 1 Batch 200 Loss 2.5677\n",
      "Epoch 1 Batch 300 Loss 2.4809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 23:01:17.494046: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for 1 epoch 800.5532758235931 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.3526\n",
      "Epoch 2 Batch 100 Loss 2.2405\n",
      "Epoch 2 Batch 200 Loss 2.2002\n",
      "Epoch 2 Batch 300 Loss 2.1097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 23:15:31.440501: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss 2.1641\n",
      "Time taken for 1 epoch 854.1089751720428 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.9129\n",
      "Epoch 3 Batch 100 Loss 1.8411\n",
      "Epoch 3 Batch 200 Loss 1.8394\n",
      "Epoch 3 Batch 300 Loss 1.8265\n",
      "Time taken for 1 epoch 811.3404030799866 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 23:29:02.944726: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch+1, batch, batch_loss.numpy()))\n",
    "        \n",
    "    if (epoch+1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "        print('Epoch {} Loss {:.4f}'.format(epoch+1, total_loss/steps_per_epoch))\n",
    "\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
    "\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ' '\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1,))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    \n",
    "    return result, sentence, attention_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict, rotation=90)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> esta es mi vida . <end>\n",
      "Predicted translation:  this is my father . <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/qdcvjm9j4vld91v373k868280000gn/T/ipykernel_1082/1296823959.py:8: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "/var/folders/nw/qdcvjm9j4vld91v373k868280000gn/T/ipykernel_1082/1296823959.py:9: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict, rotation=90)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
    "\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "translate(u'esta es mi vida.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
