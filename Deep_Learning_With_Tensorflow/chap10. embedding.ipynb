{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임베딩\n",
    "##### 1. 희소 표현 기반 임베딩\n",
    "##### 2. 횟수 기반 임베딩\n",
    "##### 3. 예측 기반 임베딩\n",
    "##### 4. 횟수/예측 기반 임베딩\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 1. 희소 표현 기반 임베딩\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "class2 = pd.read_csv(\"080263/chap10/data/class2.csv\")\n",
    "\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "onehot_encoder = preprocessing.OneHotEncoder(sparse_output=False)\n",
    "\n",
    "var = np.array(class2['class2']).reshape(-1, 1)\n",
    "train_x = onehot_encoder.fit_transform(var)\n",
    "print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 13,\n",
       " 'is': 7,\n",
       " 'last': 8,\n",
       " 'chance': 2,\n",
       " 'and': 0,\n",
       " 'if': 6,\n",
       " 'you': 15,\n",
       " 'do': 3,\n",
       " 'not': 10,\n",
       " 'have': 5,\n",
       " 'will': 14,\n",
       " 'never': 9,\n",
       " 'get': 4,\n",
       " 'any': 1,\n",
       " 'one': 11,\n",
       " 'please': 12}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 횟수 기반 임베딩\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'This is last chance',\n",
    "    'and if you do not have this chance',\n",
    "    'you will never get any chance',\n",
    "    'will you do get this one?',\n",
    "    'please, get this chance'\n",
    "]\n",
    "vect = CountVectorizer()\n",
    "vect.fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transform(['you will never get any chance']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last': 6,\n",
       " 'chance': 1,\n",
       " 'if': 5,\n",
       " 'you': 11,\n",
       " 'do': 2,\n",
       " 'not': 8,\n",
       " 'have': 4,\n",
       " 'will': 10,\n",
       " 'never': 7,\n",
       " 'get': 3,\n",
       " 'any': 0,\n",
       " 'one': 9}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words=['and', 'is', 'please', 'this']).fit(corpus)\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 5 stored elements and shape (3, 3)>\n",
      "  Coords\tValues\n",
      "  (0, 1)\t0.224324998974933\n",
      "  (0, 0)\t1.0000000000000002\n",
      "  (1, 1)\t1.0000000000000002\n",
      "  (1, 0)\t0.224324998974933\n",
      "  (2, 2)\t1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "doc = ['I like machine learning', 'I love deep learning', 'I run everyday']\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=1)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(doc)\n",
    "doc_distance = (tfidf_matrix * tfidf_matrix.T)\n",
    "print(doc_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['once',\n",
       "  'upon',\n",
       "  'a',\n",
       "  'time',\n",
       "  'in',\n",
       "  'london',\n",
       "  ',',\n",
       "  'the',\n",
       "  'darlings',\n",
       "  'went',\n",
       "  'out',\n",
       "  'to',\n",
       "  'a',\n",
       "  'dinner',\n",
       "  'party',\n",
       "  'leaving',\n",
       "  'their',\n",
       "  'three',\n",
       "  'children',\n",
       "  'wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  ',',\n",
       "  'and',\n",
       "  'michael',\n",
       "  'at',\n",
       "  'home',\n",
       "  '.'],\n",
       " ['after',\n",
       "  'wendy',\n",
       "  'had',\n",
       "  'tucked',\n",
       "  'her',\n",
       "  'younger',\n",
       "  'brothers',\n",
       "  'jhon',\n",
       "  'and',\n",
       "  'michael',\n",
       "  'to',\n",
       "  'bed',\n",
       "  ',',\n",
       "  'she',\n",
       "  'went',\n",
       "  'to',\n",
       "  'read',\n",
       "  'a',\n",
       "  'book',\n",
       "  '.'],\n",
       " ['she', 'heard', 'a', 'boy', 'sobbing', 'outside', 'her', 'window', '.'],\n",
       " ['he', 'was', 'flying', '.'],\n",
       " ['there', 'was', 'little', 'fairy', 'fluttering', 'around', 'him', '.'],\n",
       " ['wendy', 'opened', 'the', 'window', 'to', 'talk', 'to', 'him', '.'],\n",
       " ['“', 'hello', '!'],\n",
       " ['who', 'are', 'you', '?'],\n",
       " ['why', 'are', 'you', 'crying', '”', ',', 'wendy', 'asked', 'him', '.'],\n",
       " ['“', 'my', 'name', 'is', 'peter', 'pan', '.'],\n",
       " ['my',\n",
       "  'shadow',\n",
       "  'wouldn',\n",
       "  '’',\n",
       "  't',\n",
       "  'stock',\n",
       "  'to',\n",
       "  'me.',\n",
       "  '”',\n",
       "  ',',\n",
       "  'he',\n",
       "  'replied',\n",
       "  '.'],\n",
       " ['she', 'asked', 'him', 'to', 'come', 'in', '.'],\n",
       " ['peter', 'agreed', 'and', 'came', 'inside', 'the', 'room', '.'],\n",
       " ['wendy',\n",
       "  'took',\n",
       "  'his',\n",
       "  'shadow',\n",
       "  'and',\n",
       "  'sewed',\n",
       "  'it',\n",
       "  'to',\n",
       "  'his',\n",
       "  'shoe',\n",
       "  'tips',\n",
       "  '.'],\n",
       " ['now',\n",
       "  'his',\n",
       "  'shadow',\n",
       "  'followed',\n",
       "  'him',\n",
       "  'wherever',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'went',\n",
       "  '!'],\n",
       " ['he',\n",
       "  'was',\n",
       "  'delighted',\n",
       "  'and',\n",
       "  'asked',\n",
       "  'wendy',\n",
       "  '“',\n",
       "  'why',\n",
       "  'don',\n",
       "  '’',\n",
       "  't',\n",
       "  'you',\n",
       "  'come',\n",
       "  'with',\n",
       "  'me',\n",
       "  'to',\n",
       "  'my',\n",
       "  'home',\n",
       "  '.'],\n",
       " ['the', 'neverland', '.'],\n",
       " ['i',\n",
       "  'lived',\n",
       "  'there',\n",
       "  'with',\n",
       "  'my',\n",
       "  'fairy',\n",
       "  'tinker',\n",
       "  'bell.',\n",
       "  '”',\n",
       "  'wendy',\n",
       "  '?'],\n",
       " ['“', 'oh', '!'],\n",
       " ['what', 'a', 'wonderful', 'idea', '!'],\n",
       " ['let', 'me', 'wake', 'up', 'john', 'and', 'micheal', 'too', '.'],\n",
       " ['could', 'you', 'teach', 'us', 'how', 'to', 'fly', '?', '”', '.'],\n",
       " ['“', 'yes', '!'],\n",
       " ['of', 'course', '!'],\n",
       " ['get',\n",
       "  'them',\n",
       "  'we',\n",
       "  'will',\n",
       "  'all',\n",
       "  'fly',\n",
       "  'together.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'replied',\n",
       "  'and',\n",
       "  'so',\n",
       "  'it',\n",
       "  'was',\n",
       "  '.'],\n",
       " ['five',\n",
       "  'little',\n",
       "  'figures',\n",
       "  'flew',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'window',\n",
       "  'of',\n",
       "  'the',\n",
       "  'darlings',\n",
       "  'and',\n",
       "  'headed',\n",
       "  'towards',\n",
       "  'neverland',\n",
       "  '.'],\n",
       " ['as',\n",
       "  'they',\n",
       "  'flew',\n",
       "  'over',\n",
       "  'the',\n",
       "  'island',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'told',\n",
       "  'the',\n",
       "  'children',\n",
       "  'more',\n",
       "  'about',\n",
       "  'his',\n",
       "  'homeland',\n",
       "  '.'],\n",
       " ['“',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'who',\n",
       "  'get',\n",
       "  'lost',\n",
       "  'come',\n",
       "  'and',\n",
       "  'stay',\n",
       "  'with',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'and',\n",
       "  'me',\n",
       "  ',',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'told',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['the', 'indians', 'also', 'live', 'in', 'neverland', '.'],\n",
       " ['the',\n",
       "  'mermaids',\n",
       "  'live',\n",
       "  'in',\n",
       "  'the',\n",
       "  'lagoon',\n",
       "  'around',\n",
       "  'the',\n",
       "  'island',\n",
       "  '.'],\n",
       " ['and',\n",
       "  'a',\n",
       "  'very',\n",
       "  'mean',\n",
       "  'pirate',\n",
       "  'called',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'keeps',\n",
       "  'troubling',\n",
       "  'everyone',\n",
       "  '.'],\n",
       " ['“', 'crocodile', 'bit', 'his', 'one', 'arm', '.'],\n",
       " ['so',\n",
       "  'the',\n",
       "  'captain',\n",
       "  'had',\n",
       "  'to',\n",
       "  'put',\n",
       "  'a',\n",
       "  'hook',\n",
       "  'in',\n",
       "  'its',\n",
       "  'place',\n",
       "  '.'],\n",
       " ['since', 'then', 'he', 'is', 'afraid', 'of', 'crocodiles', '.'],\n",
       " ['and', 'rightly', 'so', '!'],\n",
       " ['if',\n",
       "  'the',\n",
       "  'crocodile',\n",
       "  'ever',\n",
       "  'found',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'it',\n",
       "  'will',\n",
       "  'eat',\n",
       "  'up',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'it',\n",
       "  'couldn',\n",
       "  '’',\n",
       "  't',\n",
       "  'eat',\n",
       "  'last',\n",
       "  'time.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'told',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['soon', 'they', 'landed', 'on', 'the', 'island', '.'],\n",
       " ['and',\n",
       "  'to',\n",
       "  'the',\n",
       "  'surprise',\n",
       "  'of',\n",
       "  'wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  'and',\n",
       "  'michael',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'let',\n",
       "  'them',\n",
       "  'in',\n",
       "  'through',\n",
       "  'a',\n",
       "  'small',\n",
       "  'opening',\n",
       "  'in',\n",
       "  'a',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['inside',\n",
       "  'the',\n",
       "  'tree',\n",
       "  'was',\n",
       "  'a',\n",
       "  'large',\n",
       "  'room',\n",
       "  'with',\n",
       "  'children',\n",
       "  'inside',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['somewhere',\n",
       "  'huddled',\n",
       "  'by',\n",
       "  'the',\n",
       "  'fire',\n",
       "  'in',\n",
       "  'the',\n",
       "  'corner',\n",
       "  'and',\n",
       "  'somewhere',\n",
       "  'playing',\n",
       "  'amongst',\n",
       "  'themselves',\n",
       "  '.'],\n",
       " ['their',\n",
       "  'faces',\n",
       "  'lit',\n",
       "  'up',\n",
       "  'when',\n",
       "  'they',\n",
       "  'saw',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  ',',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  ',',\n",
       "  'and',\n",
       "  'their',\n",
       "  'guests',\n",
       "  '.'],\n",
       " ['“', 'hello', 'everyone', '.'],\n",
       " ['this', 'is', 'wendy', ',', 'jhon', ',', 'and', 'michael', '.'],\n",
       " ['they',\n",
       "  'will',\n",
       "  'be',\n",
       "  'staying',\n",
       "  'with',\n",
       "  'us',\n",
       "  'from',\n",
       "  'now',\n",
       "  'on.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'introduced',\n",
       "  'them',\n",
       "  'to',\n",
       "  'all',\n",
       "  'children',\n",
       "  '.'],\n",
       " ['children', 'welcomed', 'wendy', ',', 'jhon', ',', 'and', 'michael', '.'],\n",
       " ['a', 'few', 'days', 'passed', '.'],\n",
       " ['and', 'they', 'settled', 'into', 'a', 'routine', '.'],\n",
       " ['wendy',\n",
       "  'would',\n",
       "  'take',\n",
       "  'care',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'in',\n",
       "  'the',\n",
       "  'day',\n",
       "  'and',\n",
       "  'would',\n",
       "  'go',\n",
       "  'out',\n",
       "  'with',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'and',\n",
       "  'her',\n",
       "  'brothers',\n",
       "  'in',\n",
       "  'the',\n",
       "  'evening',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'about',\n",
       "  'the',\n",
       "  'island',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'would',\n",
       "  'cook',\n",
       "  'for',\n",
       "  'them',\n",
       "  'and',\n",
       "  'stitch',\n",
       "  'new',\n",
       "  'clothes',\n",
       "  'for',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'even',\n",
       "  'made',\n",
       "  'a',\n",
       "  'lovely',\n",
       "  'new',\n",
       "  'dress',\n",
       "  'for',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  '.'],\n",
       " ['one',\n",
       "  'evening',\n",
       "  ',',\n",
       "  'as',\n",
       "  'they',\n",
       "  'were',\n",
       "  'out',\n",
       "  'exploring',\n",
       "  'the',\n",
       "  'island',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'warned',\n",
       "  'everyone',\n",
       "  'and',\n",
       "  'said',\n",
       "  ',',\n",
       "  '“',\n",
       "  'hide',\n",
       "  '!'],\n",
       " ['hide', '!'],\n",
       " ['pirates', '!'],\n",
       " ['and',\n",
       "  'they',\n",
       "  'have',\n",
       "  'kidnapped',\n",
       "  'the',\n",
       "  'indian',\n",
       "  'princess',\n",
       "  'tiger',\n",
       "  'lily',\n",
       "  '.'],\n",
       " ['they',\n",
       "  'have',\n",
       "  'kept',\n",
       "  'her',\n",
       "  'there',\n",
       "  ',',\n",
       "  'tied',\n",
       "  'up',\n",
       "  'by',\n",
       "  'the',\n",
       "  'rocks',\n",
       "  ',',\n",
       "  'near',\n",
       "  'the',\n",
       "  'water.',\n",
       "  '”',\n",
       "  'peter',\n",
       "  'was',\n",
       "  'afraid',\n",
       "  'and',\n",
       "  'the',\n",
       "  'princess',\n",
       "  'would',\n",
       "  'drown',\n",
       "  ',',\n",
       "  'is',\n",
       "  'she',\n",
       "  'fell',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water',\n",
       "  '.'],\n",
       " ['so',\n",
       "  ',',\n",
       "  'in',\n",
       "  'a',\n",
       "  'voice',\n",
       "  'that',\n",
       "  'sounded',\n",
       "  'like',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  ',',\n",
       "  'he',\n",
       "  'shouted',\n",
       "  'instructions',\n",
       "  'to',\n",
       "  'the',\n",
       "  'pirates',\n",
       "  'who',\n",
       "  'guarded',\n",
       "  'her',\n",
       "  ',',\n",
       "  '“',\n",
       "  'you',\n",
       "  'fools',\n",
       "  '!'],\n",
       " ['let', 'her', 'go', 'at', 'once', '!'],\n",
       " ['do',\n",
       "  'it',\n",
       "  'before',\n",
       "  'i',\n",
       "  'come',\n",
       "  'there',\n",
       "  'or',\n",
       "  'else',\n",
       "  'i',\n",
       "  'will',\n",
       "  'throw',\n",
       "  'each',\n",
       "  'one',\n",
       "  'of',\n",
       "  'you',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water.',\n",
       "  '”',\n",
       "  'the',\n",
       "  'pirates',\n",
       "  'got',\n",
       "  'scared',\n",
       "  'and',\n",
       "  'immediately',\n",
       "  'released',\n",
       "  'the',\n",
       "  'princes',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'quickly',\n",
       "  'dived',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water',\n",
       "  'and',\n",
       "  'swam',\n",
       "  'to',\n",
       "  'the',\n",
       "  'safety',\n",
       "  'of',\n",
       "  'her',\n",
       "  'home',\n",
       "  '.'],\n",
       " ['soon',\n",
       "  'everyone',\n",
       "  'found',\n",
       "  'out',\n",
       "  'how',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'had',\n",
       "  'rescued',\n",
       "  'the',\n",
       "  'princess',\n",
       "  '.'],\n",
       " ['when',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'found',\n",
       "  'out',\n",
       "  'how',\n",
       "  'peter',\n",
       "  'had',\n",
       "  'tricked',\n",
       "  'his',\n",
       "  'men',\n",
       "  'he',\n",
       "  'was',\n",
       "  'furious',\n",
       "  '.'],\n",
       " ['and', 'swore', 'to', 'have', 'his', 'revenge', '.'],\n",
       " ['that',\n",
       "  'night',\n",
       "  'wendy',\n",
       "  'told',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  ',',\n",
       "  'that',\n",
       "  'she',\n",
       "  'and',\n",
       "  'her',\n",
       "  'brother',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'go',\n",
       "  'back',\n",
       "  'home',\n",
       "  'since',\n",
       "  'they',\n",
       "  'missed',\n",
       "  'their',\n",
       "  'parents',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'said',\n",
       "  'if',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  'could',\n",
       "  'also',\n",
       "  'return',\n",
       "  'to',\n",
       "  'her',\n",
       "  'world',\n",
       "  'they',\n",
       "  'could',\n",
       "  'find',\n",
       "  'a',\n",
       "  'nice',\n",
       "  'home',\n",
       "  'for',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['peter', 'pan', 'didn', '’', 't', 'want', 'to', 'leave', 'neverland', '.'],\n",
       " ['but',\n",
       "  'the',\n",
       "  'sake',\n",
       "  'of',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  'he',\n",
       "  'agreed',\n",
       "  ',',\n",
       "  'although',\n",
       "  'a',\n",
       "  'bit',\n",
       "  'sadly',\n",
       "  '.'],\n",
       " ['he', 'would', 'miss', 'his', 'friends', 'dearly', '.'],\n",
       " ['the',\n",
       "  'next',\n",
       "  'morning',\n",
       "  'all',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  'left',\n",
       "  'with',\n",
       "  'wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  ',',\n",
       "  'and',\n",
       "  'michael',\n",
       "  '.'],\n",
       " ['but',\n",
       "  'on',\n",
       "  'the',\n",
       "  'way',\n",
       "  ',',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'and',\n",
       "  'his',\n",
       "  'men',\n",
       "  'kidnapped',\n",
       "  'all',\n",
       "  'of',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'tied',\n",
       "  'them',\n",
       "  'and',\n",
       "  'kept',\n",
       "  'them',\n",
       "  'on',\n",
       "  'once',\n",
       "  'of',\n",
       "  'his',\n",
       "  'ships',\n",
       "  '.'],\n",
       " ['as',\n",
       "  'soon',\n",
       "  'as',\n",
       "  'peter',\n",
       "  'found',\n",
       "  'out',\n",
       "  'about',\n",
       "  'it',\n",
       "  'he',\n",
       "  'rushed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'ship',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'swung',\n",
       "  'himself',\n",
       "  'from',\n",
       "  'a',\n",
       "  'tress',\n",
       "  'branch',\n",
       "  'and',\n",
       "  'on',\n",
       "  'to',\n",
       "  'the',\n",
       "  'deck',\n",
       "  'of',\n",
       "  'the',\n",
       "  'ship',\n",
       "  'where',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'were',\n",
       "  'tied',\n",
       "  'up',\n",
       "  '.'],\n",
       " ['he',\n",
       "  'swung',\n",
       "  'his',\n",
       "  'sword',\n",
       "  'bravely',\n",
       "  'and',\n",
       "  'threw',\n",
       "  'over',\n",
       "  'the',\n",
       "  'pirates',\n",
       "  'who',\n",
       "  'tried',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'him',\n",
       "  '.'],\n",
       " ['quickly',\n",
       "  'he',\n",
       "  'released',\n",
       "  'everyone',\n",
       "  'from',\n",
       "  'their',\n",
       "  'captor',\n",
       "  '’',\n",
       "  's',\n",
       "  'ties',\n",
       "  '.'],\n",
       " ['wendy',\n",
       "  ',',\n",
       "  'jhon',\n",
       "  ',',\n",
       "  'michael',\n",
       "  'and',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'helped',\n",
       "  'all',\n",
       "  'the',\n",
       "  'children',\n",
       "  'into',\n",
       "  'the',\n",
       "  'water',\n",
       "  ',',\n",
       "  'where',\n",
       "  'their',\n",
       "  'friends',\n",
       "  'from',\n",
       "  'the',\n",
       "  'indian',\n",
       "  'camp',\n",
       "  'were',\n",
       "  'ready',\n",
       "  'with',\n",
       "  'smaller',\n",
       "  'boats',\n",
       "  'to',\n",
       "  'take',\n",
       "  'them',\n",
       "  'to',\n",
       "  'safety',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'now',\n",
       "  'went',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  '.'],\n",
       " ['“',\n",
       "  'let',\n",
       "  'us',\n",
       "  'finished',\n",
       "  'this',\n",
       "  'forever',\n",
       "  'mr.',\n",
       "  'hook',\n",
       "  '”',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'challenged',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  '.'],\n",
       " ['“', 'yes', '!'],\n",
       " ['peter',\n",
       "  'pan',\n",
       "  ',',\n",
       "  'you',\n",
       "  'have',\n",
       "  'caused',\n",
       "  'me',\n",
       "  'enough',\n",
       "  'trouble',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'time',\n",
       "  'that',\n",
       "  'we',\n",
       "  'finished',\n",
       "  'this.',\n",
       "  '”',\n",
       "  'hook',\n",
       "  'replied',\n",
       "  '.'],\n",
       " ['with',\n",
       "  'his',\n",
       "  'sword',\n",
       "  'drawn',\n",
       "  ',',\n",
       "  'he',\n",
       "  'raced',\n",
       "  'towards',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  '.'],\n",
       " ['quick',\n",
       "  'on',\n",
       "  'his',\n",
       "  'feet',\n",
       "  ',',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'stepped',\n",
       "  'aside',\n",
       "  'and',\n",
       "  'pushed',\n",
       "  'hook',\n",
       "  'inside',\n",
       "  'the',\n",
       "  'sea',\n",
       "  'where',\n",
       "  'the',\n",
       "  'crocodile',\n",
       "  'was',\n",
       "  'waiting',\n",
       "  'to',\n",
       "  'eat',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'hook',\n",
       "  '.'],\n",
       " ['everyone',\n",
       "  'rejoiced',\n",
       "  'as',\n",
       "  'captain',\n",
       "  'hook',\n",
       "  'was',\n",
       "  'out',\n",
       "  'of',\n",
       "  'their',\n",
       "  'lives',\n",
       "  'forever',\n",
       "  '.'],\n",
       " ['everybody', 'headed', 'back', 'to', 'london', '.'],\n",
       " ['mr.', 'and', 'mrs', '.'],\n",
       " ['darling',\n",
       "  'was',\n",
       "  'so',\n",
       "  'happy',\n",
       "  'to',\n",
       "  'see',\n",
       "  'their',\n",
       "  'children',\n",
       "  'and',\n",
       "  'they',\n",
       "  'agreed',\n",
       "  'to',\n",
       "  'adopt',\n",
       "  'the',\n",
       "  'lost',\n",
       "  'children',\n",
       "  '.'],\n",
       " ['they',\n",
       "  'even',\n",
       "  'asked',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'to',\n",
       "  'come',\n",
       "  'and',\n",
       "  'live',\n",
       "  'with',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['but',\n",
       "  'peter',\n",
       "  'pan',\n",
       "  'said',\n",
       "  ',',\n",
       "  'he',\n",
       "  'never',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'up',\n",
       "  ',',\n",
       "  'so',\n",
       "  'he',\n",
       "  'and',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'will',\n",
       "  'go',\n",
       "  'back',\n",
       "  'to',\n",
       "  'neverland',\n",
       "  '.'],\n",
       " ['peter',\n",
       "  'pan',\n",
       "  'promised',\n",
       "  'everyone',\n",
       "  'that',\n",
       "  'he',\n",
       "  'will',\n",
       "  'visit',\n",
       "  'again',\n",
       "  'sometime',\n",
       "  '!'],\n",
       " ['and',\n",
       "  'he',\n",
       "  'flew',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'window',\n",
       "  'with',\n",
       "  'tinker',\n",
       "  'bell',\n",
       "  'by',\n",
       "  'his',\n",
       "  'side',\n",
       "  '.']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 예측 기반 임베딩\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "sample = open(\"080263/chap10/data/peter.txt\", \"r\", encoding=\"UTF8\")\n",
    "s = sample.read()\n",
    "f = s.replace(\"\\n\", \" \")\n",
    "\n",
    "data = []\n",
    "for i in sent_tokenize(f):\n",
    "    temp = []\n",
    "    for j in word_tokenize(i):\n",
    "        temp.append(j.lower())\n",
    "    data.append(temp)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'peter' 'wendy' - CBOW : 0.07439384\n",
      "Cosine similarity between 'peter' 'hook' - CBOW : 0.027709857\n"
     ]
    }
   ],
   "source": [
    "model1 = Word2Vec(data, min_count=1, vector_size=100, window=5, sg=0)\n",
    "print(\"Cosine similarity between 'peter' 'wendy' - CBOW :\", model1.wv.similarity('peter', 'wendy'))\n",
    "print(\"Cosine similarity between 'peter' 'hook' - CBOW :\", model1.wv.similarity('peter', 'hook'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'peter' 'wendy' - Skip Gram : 0.40088683\n",
      "Cosine similarity between 'peter' 'hook' - Skip Gram : 0.52016735\n"
     ]
    }
   ],
   "source": [
    "model2 = Word2Vec(data, min_count=1, vector_size=100, window=5, sg=1)\n",
    "print(\"Cosine similarity between 'peter' 'wendy' - Skip Gram :\", model2.wv.similarity('peter', 'wendy'))\n",
    "print(\"Cosine similarity between 'peter' 'hook' - Skip Gram :\", model2.wv.similarity('peter', 'hook'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4592452\n",
      "0.043825686\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import FastText\n",
    "\n",
    "model = FastText(\"080263/chap10/data/peter.txt\", vector_size=4, window=3, min_count=1, epochs=10)\n",
    "sim_score = model.wv.similarity('peter', 'wendy')\n",
    "print(sim_score)\n",
    "sim_score = model.wv.similarity('peter', 'hook')\n",
    "print(sim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model_kr = KeyedVectors.load_word2vec_format(\"080263/chap10/data/wiki.ko.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노력함 0.796721339225769\n",
      "노력중 0.7502310872077942\n",
      "노력만 0.7195297479629517\n",
      "노력과 0.7137250900268555\n",
      "노력의 0.6944872140884399\n",
      "노력가 0.6931817531585693\n",
      "노력이나 0.6855085492134094\n",
      "노력없이 0.6761217713356018\n",
      "노력맨 0.6756712198257446\n",
      "노력보다는 0.6753138303756714\n"
     ]
    }
   ],
   "source": [
    "for similar_word in model_kr.similar_by_word('노력'):\n",
    "    print(similar_word[0], similar_word[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('초식동물', 0.7804122567176819)\n"
     ]
    }
   ],
   "source": [
    "similarities = model_kr.most_similar(positive=['동물', '육식동물'], negative=['사람'])\n",
    "print(similarities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/qdcvjm9j4vld91v373k868280000gn/T/ipykernel_17578/2666281902.py:13: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_file, word2vec_glove_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 횟수/예측 기반 임베딩\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_file = datapath(\"/Users/minwoo/dev/Awesome-DL-Study/Deep_Learning_With_Tensorflow/080263/chap10/data/glove.6B.100d.txt\")\n",
    "word2vec_glove_file = get_tmpfile(\"glove.6B.100d.word2vec.txt\")\n",
    "glove2word2vec(glove_file, word2vec_glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('legislation', 0.8072139620780945),\n",
       " ('proposal', 0.7306863069534302),\n",
       " ('senate', 0.7142540812492371),\n",
       " ('bills', 0.704440176486969),\n",
       " ('measure', 0.6958035230636597),\n",
       " ('passed', 0.6906244158744812),\n",
       " ('amendment', 0.6846879720687866),\n",
       " ('provision', 0.6845566630363464),\n",
       " ('plan', 0.6816462874412537),\n",
       " ('clinton', 0.6663140058517456)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n",
    "model.most_similar('bill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kazushige', 0.4834350347518921),\n",
       " ('askerov', 0.4778185784816742),\n",
       " ('lakpa', 0.46915262937545776),\n",
       " ('ex-gay', 0.45713332295417786),\n",
       " ('tadayoshi', 0.4522107243537903),\n",
       " ('turani', 0.44810065627098083),\n",
       " ('saglam', 0.4469599425792694),\n",
       " ('aijun', 0.4435270130634308),\n",
       " ('adjustors', 0.44235295057296753),\n",
       " ('nyum', 0.4423117935657501)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(negative=['cherry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7698541283607483),\n",
       " ('monarch', 0.6843380331993103),\n",
       " ('throne', 0.6755736470222473),\n",
       " ('daughter', 0.6594556570053101),\n",
       " ('princess', 0.6520534157752991),\n",
       " ('prince', 0.6517034769058228),\n",
       " ('elizabeth', 0.6464518308639526),\n",
       " ('mother', 0.631171703338623),\n",
       " ('emperor', 0.6106470823287964),\n",
       " ('wife', 0.6098655462265015)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "champagne\n",
      "longest\n"
     ]
    }
   ],
   "source": [
    "def analogy(x1, x2, y1):\n",
    "    result = model.most_similar(positive=[x1, x2], negative=[y1])\n",
    "    return result[0][0]\n",
    "\n",
    "print(analogy('beer', 'france', 'australia'))\n",
    "print(analogy('tallest', 'long', 'tall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cereal\n"
     ]
    }
   ],
   "source": [
    "print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 트랜스포머 어텐션\n",
    "##### 1. seq2seq\n",
    "##### 2. Bert\n",
    "##### 3. 엘모"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq2seq\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import unicodedata\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "     return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1\", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.rstrip().strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "sp_sentence = u\"¿ Puedo tomar prestado este libro?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')] for l in lines[:num_examples]]\n",
    "    return zip(*word_pairs)\n",
    "\n",
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    return tensor, lang_tokenizer\n",
    "\n",
    "def load_dataset(path, num_examples=None):\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 30000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(\"080263/chap10/data/spa.txt\", num_examples)\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train) // BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "vocab_targ_size = len(targ_lang.word_index) + 1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(\n",
    "            self.enc_units,\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            recurrent_initializer='glorot_uniform'\n",
    "        )\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "    \n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(EDAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(\n",
    "            self.dec_units,\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            recurrent_initializer='glorot_uniform'\n",
    "        )\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        self.attention = EDAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights\n",
    "    \n",
    "decoder = Decoder(vocab_targ_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ += mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(\n",
    "    optimizer=optimizer,\n",
    "    encoder=encoder,\n",
    "    decoder=decoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 8.2452\n",
      "Epoch 1 Batch 100 Loss 2.8362\n",
      "Epoch 1 Batch 200 Loss 2.6111\n",
      "Epoch 1 Batch 300 Loss 2.4548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 23:50:38.859282: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for 1 epoch 795.0368001461029 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.1791\n",
      "Epoch 2 Batch 100 Loss 2.3032\n",
      "Epoch 2 Batch 200 Loss 2.0180\n",
      "Epoch 2 Batch 300 Loss 1.9598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 00:04:19.440715: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss 2.1275\n",
      "Time taken for 1 epoch 820.7724859714508 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.7589\n",
      "Epoch 3 Batch 100 Loss 1.7795\n",
      "Epoch 3 Batch 200 Loss 1.7298\n",
      "Epoch 3 Batch 300 Loss 1.6593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 00:19:00.685468: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for 1 epoch 881.0536417961121 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.4803\n",
      "Epoch 4 Batch 100 Loss 1.4562\n",
      "Epoch 4 Batch 200 Loss 1.3176\n",
      "Epoch 4 Batch 300 Loss 1.2523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 00:35:13.460210: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss 1.3968\n",
      "Time taken for 1 epoch 972.9137089252472 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.1947\n",
      "Epoch 5 Batch 100 Loss 1.1778\n",
      "Epoch 5 Batch 200 Loss 1.1255\n",
      "Epoch 5 Batch 300 Loss 1.1850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 00:51:16.058734: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for 1 epoch 962.4593639373779 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.9338\n",
      "Epoch 6 Batch 100 Loss 0.9555\n",
      "Epoch 6 Batch 200 Loss 0.9633\n",
      "Epoch 6 Batch 300 Loss 0.9474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 01:07:02.929831: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss 0.9490\n",
      "Time taken for 1 epoch 947.0492639541626 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.8128\n",
      "Epoch 7 Batch 100 Loss 0.7814\n",
      "Epoch 7 Batch 200 Loss 0.7989\n",
      "Epoch 7 Batch 300 Loss 0.8670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 01:22:45.569742: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for 1 epoch 942.4614200592041 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.8104\n",
      "Epoch 8 Batch 100 Loss 0.7338\n",
      "Epoch 8 Batch 200 Loss 0.7522\n",
      "Epoch 8 Batch 300 Loss 0.7858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 01:38:09.978208: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss 0.7518\n",
      "Time taken for 1 epoch 924.5768098831177 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.7063\n",
      "Epoch 9 Batch 100 Loss 0.6738\n",
      "Epoch 9 Batch 200 Loss 0.7391\n",
      "Epoch 9 Batch 300 Loss 0.6909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 01:53:35.866492: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for 1 epoch 925.7210319042206 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.6752\n",
      "Epoch 10 Batch 100 Loss 0.6597\n",
      "Epoch 10 Batch 200 Loss 0.6506\n",
      "Epoch 10 Batch 300 Loss 0.7105\n",
      "Epoch 10 Loss 0.6865\n",
      "Time taken for 1 epoch 921.9649829864502 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 02:08:57.676419: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch+1, batch, batch_loss.numpy()))\n",
    "        \n",
    "    if (epoch+1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "        print('Epoch {} Loss {:.4f}'.format(epoch+1, total_loss/steps_per_epoch))\n",
    "\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
    "\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ' '\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1,))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    \n",
    "    return result, sentence, attention_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict, rotation=90)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> esta es mi vida . <end>\n",
      "Predicted translation:  this is my life . <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/qdcvjm9j4vld91v373k868280000gn/T/ipykernel_1082/1296823959.py:8: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "/var/folders/nw/qdcvjm9j4vld91v373k868280000gn/T/ipykernel_1082/1296823959.py:9: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict, rotation=90)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
    "\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "translate(u'esta es mi vida.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
